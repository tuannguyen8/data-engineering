# -*- coding: utf-8 -*-
"""data-gathering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jDowrPaOwukSDXTbRy92B_GjOrSyClaY
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from urllib.request import urlopen
from bs4 import BeautifulSoup
import re

# Import parameters from pylab module
from pylab import rcParams
from matplotlib import rcParams

# Specify the URL containing the dataset
#url = "http://www.hubertiming.com/results/2017GPTR10K"
url = "https://www.hubertiming.com/results/2023WyEasterLong"
html = urlopen(url)

# Create a Beautiful Soup object from the html
soup = BeautifulSoup(html, 'lxml')

# Get the title of the page
title = soup.title
# print(title)

# Get and print the text of the webpage
text = soup.get_text()
# print(soup.text)  # Commented out to avoid large output

# Extract all hyperlinks within the webpage
all_links = soup.find_all("a")
# for link in all_links:
    # print(link.get("href"))

# Extract table rows
rows = soup.find_all('tr')
# print(rows[:10])  # Print the first 10 rows for sanity check

# Print out the cells of the rows
for row in rows:
    row_td = row.find_all('td')
# print(row_td)
type(row_td)

# Remove html tags using Beautiful Soup
str_cells = str(row_td)
cleantext = BeautifulSoup(str_cells, "lxml").get_text()
# print(cleantext)

# Extract text between html tags for each row using regular expressions
list_rows = []
for row in rows:
    cells = row.find_all('td')
    str_cells = str(cells)
    clean = re.compile('<.*?>')
    clean2 = (re.sub(clean, '', str_cells))
    list_rows.append(clean2)
    # print(clean2)

# Convert the list into a pandas dataframe
df = pd.DataFrame(list_rows)
df.head(10)

# Data Transformation
# Split the "0" column into multiple columns at the comma position
df1 = df[0].str.split(',', expand=True)
df1.head(10)

# Remove the opening square bracket on column "0"
df1[0] = df1[0].str.strip('[')
df1.head(10)

# Get the table headers
col_labels = soup.find_all('th')

# Extract text in between html tags for table headers
all_header = []
col_str = str(col_labels)
cleantext2 = BeautifulSoup(col_str, "lxml").get_text()
all_header.append(cleantext2)
# print(all_header)

# Convert the table headers to a new pandas dataframe
df2 = pd.DataFrame(all_header)
df2.head()

# Split column "0" into multiple columns at the comma position for the headers
df3 = df2[0].str.split(',', expand=True)
df3.head()

# Concatenate the two dataframes into one
frames = [df3, df1]
df4 = pd.concat(frames)
df4.head(10)

# Re-configure the data frame so that the first row is the table header
df5 = df4.rename(columns=df4.iloc[0])
df5.head()

# Get an overview of the data
df5.info()
df5.shape

# Drop all rows with any missing values
df6 = df5.dropna(axis=0, how='any')
df6.info()
df6.shape

# Drop the redundant header row
df7 = df6.drop(df6.index[0])
df7.head()

# Rename the '[Place' and ' Team]' columns
# df7.rename(columns={'[Place': 'Place'}, inplace=True)
# df7.rename(columns={' Team]': 'Team'}, inplace=True)
# df7.head()

# # Remove the closing bracket for cells in the "Team" column
# df7['Team'] = df7['Team'].str.strip(']')
# df7.head()

# Data Analysis and Visualization
# Convert "Chip Time" to minutes
time_list = df7[' Time'].tolist()

# Convert 'Chip Time' to minutes
time_mins = []

time_mins = []
for i in time_list:
    try:
        # print("testing: ", i)
        parts = i.split(':')
        if len(parts) == 3:  # Format is HH:MM:SS
            h, m, s = parts
        elif len(parts) == 2:  # Format is MM:SS
            h = 0
            m, s = parts
        else:
            raise ValueError(f"Unexpected time format: {i}")

        # Convert to minutes
        math = (int(h) * 3600 + int(m) * 60 + int(s)) / 60
        time_mins.append(math)
    except ValueError as e:
        print(f"Error processing time '{i}': {e}")

print(time_mins)

# Graphs
df7['Runner_mins'] = time_mins
df7.head()
df7.describe(include=[np.number])
from pylab import rcParams

df7.boxplot(column='Runner_mins')
plt.grid(True, axis='y')
plt.ylabel('Chip Time')
plt.xticks([1], ['Runners'])

x = df7['Runner_mins']
ax = sns.distplot(x, hist=True, kde=True, rug=False, color='m', bins=25, hist_kws={'edgecolor':'black'})
plt.show()

f_fuko = df7.loc[df7[' Gender']==' F']['Runner_mins']
m_fuko = df7.loc[df7[' Gender']==' M']['Runner_mins']
sns.distplot(f_fuko, hist=True, kde=True, rug=False, hist_kws={'edgecolor':'black'}, label='Female')
sns.distplot(m_fuko, hist=False, kde=True, rug=False, hist_kws={'edgecolor':'black'}, label='Male')
plt.legend()

g_stats = df7.groupby(" Gender", as_index=True).describe()
print(g_stats)
df7.boxplot(column='Runner_mins', by=' Gender')
plt.ylabel('Chip Time')
plt.suptitle("")